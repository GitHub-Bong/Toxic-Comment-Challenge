{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0330-PretrainedEmbedding-Word2Vec,Glove.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitHub-Bong/Toxic-Comment-Challenge/blob/master/0330_PretrainedEmbedding_Word2Vec%2CGlove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8yZL8gdqw6Y"
      },
      "source": [
        "# Reference\n",
        "[\n",
        "Do Pretrained Embeddings Give You The Extra Edge?](https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge)\n",
        "<br/>\n",
        "[Pre-trained Word Embedding](https://wikidocs.net/33793)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0iPBHldqiow",
        "outputId": "1b03ec21-b148-454c-fd77-6d7ad51dee94"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkTlZDXerGzG"
      },
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZGvPFsZrfJY"
      },
      "source": [
        "# **Data Preprocessing**\n",
        "\n",
        "03/30 Use Word2Vec, GloVe, FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqzPzI7CrZ5d"
      },
      "source": [
        "train = pd.read_csv('/content/drive/Shareddrives/SOGANG Parrot/train.csv/train.csv')\n",
        "test = pd.read_csv('/content/drive/Shareddrives/SOGANG Parrot/test.csv/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr9XPYlor_52"
      },
      "source": [
        "**Check for nulls**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeDUOooortaG",
        "outputId": "33809258-8a58-4d4a-ad2a-60de08293c2b"
      },
      "source": [
        "train.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               False\n",
              "comment_text     False\n",
              "toxic            False\n",
              "severe_toxic     False\n",
              "obscene          False\n",
              "threat           False\n",
              "insult           False\n",
              "identity_hate    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgZXH8rlrvW3",
        "outputId": "7a36e02f-0cb3-4a04-83d1-e92bb82c12be"
      },
      "source": [
        "test.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id              False\n",
              "comment_text    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQXkLp2Brgk5"
      },
      "source": [
        "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "y = train[list_classes].values # y.shape (159571, 6)\n",
        "list_sentences_train = train[\"comment_text\"] # (159571,)\n",
        "list_sentences_test = test[\"comment_text\"] # (153164,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj0tYUOPsFMx"
      },
      "source": [
        "# Tokenization \n",
        " sentence into unique words     \n",
        " ex) \"I love cats and love dogs\" -> [\"I\",\"love\",\"cats\",\"and\",\"dogs\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w-eykjAsHUO"
      },
      "source": [
        "# **Indexing**\n",
        "put the words in a dictionary-like structure and give them an index each     \n",
        "ex) {1:\"I\",2:\"love\",3:\"cats\",4:\"and\",5:\"dogs\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eINA-ANCsHrG"
      },
      "source": [
        "# **Index Representation**\n",
        "represent the sequence of words in the comments in the form of index     \n",
        "ex) [\"I\",\"love\",\"cats\",\"and\",\"dogs\"] -> [1,2,3,4,5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_--s02nesL2Z"
      },
      "source": [
        "In Keras, all the above steps can be done in 4 lines of code     \n",
        "we have to *define the number of unique words* in our dictionary when tokenizing the sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aow_Y_CRr2G2"
      },
      "source": [
        "max_features = 20000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "# list_tokenized_train[:1] = [[688,75,1,126,130, ,,, ]]\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
        "# list_tokenized_test[:1] = [[2665,655,8849,656, ,,, ]]\n",
        "\n",
        "# tokenizer.word_counts = OrderedDict([('explanation', 1771),('why', 17818),('the', 496540),('edits', 9957), ,,, ])\n",
        "# tokenizer.word_index = {'the': 1,'to': 2,'of': 3,'and': 4, ,,, }\n",
        "# len(tokenizer.word_index) 210337"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgnIJvJWr8BN"
      },
      "source": [
        "**We may have a problem**     \n",
        "ex)        \n",
        "Comment #1: [8,9,3,7,3,6,3,6,3,6,2,3,4,9]      \n",
        "Comment #2: [1,2]      \n",
        "<br/>        \n",
        "\n",
        "we have to feed a stream of data that has a __consistent length(fixed number of features)__       \n",
        "<br/>\n",
        "<br/>\n",
        "     \n",
        "## We have to use \"padding\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo8HmIEMr29G"
      },
      "source": [
        "maxlen = 200\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen) # (159571, 200)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen) # (153164, 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR6Szfo0tHIP"
      },
      "source": [
        "# Pretrained\n",
        "There are quite a __few GLOVE embeddings__ in Kaggle datasets     \n",
        "-> Use the one that was trained based on __Twitter text__\n",
        "<br/><br/>\n",
        "Use the __Word2Vec embeddings__ which has been trained using __Google Negative News text corpus__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4pnM_K_wfUN"
      },
      "source": [
        "# GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W0GjwBnzaDE"
      },
      "source": [
        "### Input Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2698FLexgzH"
      },
      "source": [
        "inp = Input(shape=(maxlen, )) #maxlen=200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgDSpltAxjQh"
      },
      "source": [
        "**Pass it to Embedding layer**\n",
        "<br/>\n",
        "<br/>\n",
        "\"__trainable = False__\" \n",
        "<br/>\n",
        "to tell Keras not to retrain the embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnNssfyhzgGc"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Azl9DpH7Oac",
        "outputId": "d81a7f85-6dbe-41d0-a91c-67ae3ef6f9c2"
      },
      "source": [
        "embedding_dict = dict()\n",
        "f = open('/content/drive/Shareddrives/SOGANG Parrot/glove.twitter.27B.25d.txt/glove.twitter.27B.25d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in f:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32') # 100\n",
        "    embedding_dict[word] = word_vector_arr\n",
        "f.close()\n",
        "print('%s개의 Embedding vector가 있습니다.' % len(embedding_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193515개의 Embedding vector가 있습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNhf77lL7kPz",
        "outputId": "e8c8a3fd-31bd-421c-ed19-755dfffa6ddb"
      },
      "source": [
        "print(embedding_dict['respectable'])\n",
        "print(len(embedding_dict['respectable']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.49053  -0.43373  -1.4828    0.07678   0.77266   1.0036   -0.16272\n",
            " -1.2494   -0.13092  -1.03     -1.0419    0.35045  -1.9792    0.53035\n",
            " -0.070342  0.4989    0.85868  -0.080579  0.13071   0.40617   0.68475\n",
            "  0.7763   -0.98371  -0.89656  -1.1979  ]\n",
            "25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfWw-D4-2mPa",
        "outputId": "a5ec675e-8da5-436c-f0d7-6b62ab5a8652"
      },
      "source": [
        "print(type(word_vector))\n",
        "print(len(word_vector))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBc4FVMi7oN-",
        "outputId": "bfdc2f9e-939b-4375-e3ab-151b115b7048"
      },
      "source": [
        "embedding_matrix = np.zeros((len(tokenizer.word_index)+1, 25)) # will delete first row\n",
        "np.shape(embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210338, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUuer7t08fWc"
      },
      "source": [
        "for word, i in tokenizer.word_index.items(): \n",
        "    temp = embedding_dict.get(word) \n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_-zXmfr9Csq",
        "outputId": "b3f76ad2-1991-468a-9837-dc1b2f8320fc"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210338, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgQBdbK0-oQs",
        "outputId": "b908c3fe-f445-4357-91e7-ab188979ef7f"
      },
      "source": [
        "embedding_matrix.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8doU3V4_2eM",
        "outputId": "89519683-5d43-4924-ddd2-4813fed417fc"
      },
      "source": [
        "embedding_matrix = np.delete(embedding_matrix,0,axis=0) # delete first row\n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210337, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxMMJjq-Fvbe"
      },
      "source": [
        "### **Save embedding_matrix**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2_so_fjF9kZ"
      },
      "source": [
        "np.save('/content/drive/Shareddrives/SOGANG Parrot/pretrained-embed-Glove.npy',embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdFXZgXlGPW9",
        "outputId": "471be370-a90b-47a7-b90c-2e6c91e7e4e4"
      },
      "source": [
        "embedding_matrix = np.load('/content/drive/Shareddrives/SOGANG Parrot/pretrained-embed-Glove.npy')\n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210337, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kNwJiFxxj08"
      },
      "source": [
        "x = Embedding(len(tokenizer.word_index), embedding_matrix.shape[1],\n",
        "              weights=[embedding_matrix],trainable=False)(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWPZPbJX0HPF"
      },
      "source": [
        "**Output of Embedding layer is <br/> 3-D tensor of (None, 200, 25)**\n",
        "\n",
        "<br/>= array of sentence\n",
        "<br/>\n",
        "For each words(200), there is an array of 25 coordinates "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiHQid85AWjz"
      },
      "source": [
        "**Feed this Tensor into the Bidirectional LSTM layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOuJUlqRAc-p"
      },
      "source": [
        "### Bidirectional LSTM Layer     \n",
        "LSTM takes in a tensor of [Batch Size, Time Steps, Number of Inputs]     \n",
        "->     \n",
        "3-D tensor of (None, 200, 25) into the LSTM layer     \n",
        "<br/>\n",
        "\n",
        "The output dimension of LSTM layer has doubled to 120 \n",
        "<br/>\n",
        "because 60 dimensions are used for forward, and another 60 are used for reverse.     \n",
        "<br/>\n",
        "<br/>\n",
        " \n",
        "   \n",
        "![image](https://i.imgur.com/jaKiP0S.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qkzCufJBfMi"
      },
      "source": [
        "### LSTM Drop out and recurrent drop out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVN4u1JBzYeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c9bd229-2f1b-4db3-d003-cd95b53b8a57"
      },
      "source": [
        "x = Bidirectional(LSTM(60, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBTCKOVhBrCi"
      },
      "source": [
        "### MaxPooling\n",
        "We need to reshape the 3D tensor into a 2D one     \n",
        "->     \n",
        "Use a __Global Max Pooling layer__      \n",
        "which is traditionally used in CNN problems to reduce the dimensionality of image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q6s-UnKBhUI"
      },
      "source": [
        "x = GlobalMaxPool1D()(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU-SmlYiBuwQ"
      },
      "source": [
        "### Dropout Layer\n",
        "Pass it to a __Dropout layer__ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqa_5JEMBs7X"
      },
      "source": [
        "x = Dropout(0.1)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fNW1OJZByXZ"
      },
      "source": [
        "### Dense Layer\n",
        "Connect the output of drop out layer to a __densely connected layer__      \n",
        "and make them passes through a __RELU function__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIsuqJD7BwtX"
      },
      "source": [
        "x = Dense(50, activation=\"relu\")(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv2Pf8FTB3OB"
      },
      "source": [
        "### Dropout Layer\n",
        "Feed the output into a Dropout layer again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX7plE_lB0x2"
      },
      "source": [
        "x = Dropout(0.1)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xZBLSVUB5vZ"
      },
      "source": [
        "### Dense Layer\n",
        "Finally, feed the output into a __Sigmoid layer__     \n",
        "Reason      \n",
        "we are trying to achieve a __binary classification__  for each of the 6 labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8F-KCytB4vG"
      },
      "source": [
        "x = Dense(6, activation=\"sigmoid\")(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48i_sM6_B-Fy"
      },
      "source": [
        "### Define the inputs, outputs and configure the learning process <br/><br/> Set Adam optimizer to optimize loss function <br/><br/> Set binary_crossentropy to be a loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSFd_gIoB7SG"
      },
      "source": [
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNEBSD4iCCdL"
      },
      "source": [
        "## A list of 32 padded, indexed sentence for each batch<br/><br/>Split 10% of the data as a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCq-C7eSCA9H",
        "outputId": "0aef62a1-dc09-42f4-aa7a-def15a49cf1c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 200, 25)           5258425   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200, 120)          41280     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                6050      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 5,306,061\n",
            "Trainable params: 47,636\n",
            "Non-trainable params: 5,258,425\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJAR16X7CE6v"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "#checkpoint\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/Shareddrives/SOGANG Parrot/pretrained-embed-Glove.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "batch_size = 512\n",
        "epochs = 2\n",
        "hist = model.fit(X_t,y, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint], validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiTXt_PqIjEF"
      },
      "source": [
        "model = load_model('/content/drive/Shareddrives/SOGANG Parrot/pretrained-embed-Glove.hdf5')\n",
        "y_test = model.predict(X_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyn9yIZUJUjr"
      },
      "source": [
        "sample_submission = pd.read_csv(\"/content/drive/Shareddrives/SOGANG Parrot/sample_submission.csv/sample_submission.csv\")\n",
        "\n",
        "sample_submission[list_classes] = y_test\n",
        "\n",
        "sample_submission.to_csv(\"/content/drive/Shareddrives/SOGANG Parrot/baseline/20210331-pretrained-embed-Glove.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhE3GfjgC3cz"
      },
      "source": [
        "----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnaq2VCOC55x"
      },
      "source": [
        "---------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71ib__mjC7qZ"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypFDjE0IC-Cm",
        "outputId": "b08e3e51-6f89-481a-a9d7-2ce6d11959cb"
      },
      "source": [
        "word2vecDict = word2vec.KeyedVectors.load_word2vec_format(\"/content/drive/Shareddrives/SOGANG Parrot/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin\", binary=True)\n",
        "print(word2vecDict.vectors.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CFqPJicDHDh",
        "outputId": "58aeb68a-f798-4133-ef50-3c81eddd1f18"
      },
      "source": [
        "embedding_matrix = np.zeros((len(tokenizer.word_index)+1, 300)) # will delete first row\n",
        "np.shape(embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210338, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QUh1Hj5EgmV"
      },
      "source": [
        "def get_vector(word):\n",
        "    if word in word2vecDict:\n",
        "        return word2vecDict[word]\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQluSxAZEiXa"
      },
      "source": [
        "for word, i in tokenizer.word_index.items(): \n",
        "    temp = get_vector(word) \n",
        "    if temp is not None: \n",
        "        embedding_matrix[i] = temp "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qezS6layHG0q",
        "outputId": "39f38c48-40cc-4a95-bbd0-1d3dfa4c6d35"
      },
      "source": [
        "embedding_matrix = np.delete(embedding_matrix,0,axis=0) # delete first row \n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210337, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuEdkJVggpKU"
      },
      "source": [
        "np.save('/content/drive/Shareddrives/SOGANG Parrot/pretrained-embed-Word2Vec.npy',embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbBJglLTg0yy",
        "outputId": "399b9f59-b3f8-4cdf-c48c-5692c45e0f39"
      },
      "source": [
        "embedding_matrix = np.load('/content/drive/Shareddrives/SOGANG Parrot/pretrained-embed-Word2Vec.npy')\n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210337, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRKVTDopEk_q",
        "outputId": "4eba5c6f-a80e-433d-95cc-c743d14f67b5"
      },
      "source": [
        "print(word2vecDict['nice'])\n",
        "print(word2vecDict['nice'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.15820312  0.10595703 -0.18945312  0.38671875  0.08349609 -0.26757812\n",
            "  0.08349609  0.11328125 -0.10400391  0.17871094 -0.12353516 -0.22265625\n",
            " -0.01806641 -0.25390625  0.13183594  0.0859375   0.16113281  0.11083984\n",
            " -0.11083984 -0.0859375   0.0267334   0.34570312  0.15136719 -0.00415039\n",
            "  0.10498047  0.04907227 -0.06982422  0.08642578  0.03198242 -0.02844238\n",
            " -0.15722656  0.11865234  0.36132812  0.00173187  0.05297852 -0.234375\n",
            "  0.11767578  0.08642578 -0.01123047  0.25976562  0.28515625 -0.11669922\n",
            "  0.38476562  0.07275391  0.01147461  0.03466797  0.18164062 -0.03955078\n",
            "  0.04199219  0.01013184 -0.06054688  0.09765625  0.06689453  0.14648438\n",
            " -0.12011719  0.08447266 -0.06152344  0.06347656  0.3046875  -0.35546875\n",
            " -0.2890625   0.19628906 -0.33203125 -0.07128906  0.12792969  0.09619141\n",
            " -0.12158203 -0.08691406 -0.12890625  0.27734375  0.265625    0.1796875\n",
            "  0.12695312  0.06298828 -0.34375    -0.05908203  0.0456543   0.171875\n",
            "  0.08935547  0.14648438 -0.04638672 -0.00842285 -0.0279541   0.234375\n",
            " -0.07470703 -0.13574219  0.00378418  0.19433594  0.05664062 -0.05419922\n",
            "  0.06176758  0.14160156 -0.24121094  0.02539062 -0.15917969 -0.10595703\n",
            "  0.11865234  0.24707031 -0.13574219 -0.20410156 -0.30078125  0.07910156\n",
            " -0.04394531  0.02026367 -0.05786133  0.2109375   0.13574219  0.08349609\n",
            " -0.0098877  -0.10546875 -0.08105469  0.03735352 -0.10351562 -0.10205078\n",
            "  0.23925781 -0.21875     0.05151367  0.06738281  0.07617188  0.04638672\n",
            "  0.03198242 -0.07275391  0.14550781  0.04858398 -0.05664062 -0.07470703\n",
            " -0.0030365  -0.09277344 -0.11083984 -0.03320312 -0.15234375 -0.12207031\n",
            "  0.09814453  0.375       0.00454712 -0.10009766  0.02734375  0.30078125\n",
            " -0.0390625   0.30078125 -0.04541016 -0.00424194  0.13671875 -0.18945312\n",
            " -0.21777344  0.12695312 -0.02746582 -0.18164062  0.08984375 -0.23339844\n",
            "  0.203125    0.2734375  -0.26953125  0.15332031 -0.20703125 -0.01153564\n",
            "  0.12451172  0.05395508 -0.23535156 -0.01409912 -0.09765625  0.20800781\n",
            "  0.19335938  0.14746094  0.28710938 -0.23046875  0.01965332 -0.09619141\n",
            " -0.0703125  -0.04174805 -0.17578125  0.0007019   0.10546875  0.10351562\n",
            "  0.02478027  0.35742188  0.17382812 -0.09570312 -0.18359375  0.23242188\n",
            " -0.14453125 -0.20410156 -0.01867676  0.06640625 -0.2265625  -0.00582886\n",
            " -0.08642578  0.02416992 -0.07324219 -0.29882812 -0.15625     0.07666016\n",
            "  0.19628906 -0.20410156  0.09863281 -0.01672363 -0.18652344 -0.12353516\n",
            " -0.16015625 -0.10058594  0.21777344  0.09375    -0.10058594 -0.03637695\n",
            "  0.15136719 -0.02526855 -0.23730469  0.03417969 -0.00604248  0.15625\n",
            " -0.14257812  0.18066406 -0.35351562  0.25        0.13085938 -0.04296875\n",
            "  0.17089844  0.20507812  0.00680542 -0.08251953 -0.06738281  0.22167969\n",
            " -0.16308594 -0.16699219 -0.02087402  0.11035156  0.06054688 -0.04223633\n",
            " -0.17285156  0.05029297 -0.19824219  0.01495361  0.06542969  0.03271484\n",
            "  0.14453125 -0.08691406 -0.11035156 -0.1484375   0.09667969  0.22363281\n",
            "  0.23535156  0.08398438  0.18164062 -0.10595703 -0.04296875  0.11572266\n",
            " -0.00153351  0.0534668  -0.1328125  -0.33203125 -0.08251953  0.30664062\n",
            "  0.22363281  0.27929688  0.09082031 -0.18066406 -0.00613403 -0.09423828\n",
            " -0.21289062  0.01965332 -0.08105469 -0.06689453 -0.31835938 -0.08447266\n",
            "  0.13574219  0.0625      0.07080078 -0.14257812 -0.11279297  0.01452637\n",
            " -0.06689453  0.03881836  0.19433594  0.09521484  0.11376953 -0.12451172\n",
            "  0.13769531 -0.18847656 -0.05224609  0.15820312  0.09863281 -0.04370117\n",
            " -0.06054688  0.21679688  0.04077148 -0.14648438 -0.18945312 -0.25195312\n",
            " -0.16894531 -0.08642578 -0.08544922  0.18945312 -0.14648438  0.13476562\n",
            " -0.04077148  0.03271484  0.08935547 -0.26757812  0.00836182 -0.21386719]\n",
            "(300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axfJ88iVEmoj",
        "outputId": "85bbb60d-c6df-40fd-f59f-1ccb7516f141"
      },
      "source": [
        "print('단어 nice의 정수 인덱스 :', tokenizer.word_index['nice'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 nice의 정수 인덱스 : 547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNcoFu8DFUUT"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUymF9RNFVpm"
      },
      "source": [
        "inp = Input(shape=(maxlen, )) #maxlen=200\n",
        "x = Embedding(len(tokenizer.word_index), embedding_matrix.shape[1],\n",
        "              weights=[embedding_matrix],trainable=False)(inp)\n",
        "x = Bidirectional(LSTM(60, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)              \n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(50, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(6, activation=\"sigmoid\")(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWF1H-7jF1ii"
      },
      "source": [
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDG6neK9F3pI",
        "outputId": "6ebe00a8-ba04-4869-d720-eb11105d7321"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 200, 300)          63101100  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200, 120)          173280    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                6050      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 63,280,736\n",
            "Trainable params: 179,636\n",
            "Non-trainable params: 63,101,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "6hLSnyyWHOdd",
        "outputId": "dd6723de-099f-4ca8-9f3d-91bdad5a50f2"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 2\n",
        "hist = model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "   7/4488 [..............................] - ETA: 1:02:59 - loss: 0.6866 - accuracy: 0.5058"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4e0f2043adf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkMKEZVnHRBV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}