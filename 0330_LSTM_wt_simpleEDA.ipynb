{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0330-LSTM_wt_simpleEDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitHub-Bong/Toxic-Comment-Challenge/blob/master/0330_LSTM_wt_simpleEDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K9WQsrfpdm7"
      },
      "source": [
        "# Reference\n",
        "[For Beginners Tackling Toxic Using Keras](https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwkZUQmrX47-",
        "outputId": "dc7e5098-79ce-416d-a2e5-443b9287036d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRKc2jQmX0Xy"
      },
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl6JYxjdZaQV"
      },
      "source": [
        "# **Data Preprocessing**\n",
        "\n",
        "03/30 check for nulls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGhwb_Q1YTsd"
      },
      "source": [
        "train = pd.read_csv('/content/drive/Shareddrives/SOGANG Parrot/train.csv/train.csv')\n",
        "test = pd.read_csv('/content/drive/Shareddrives/SOGANG Parrot/test.csv/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "YFGtJolBYcX_",
        "outputId": "44f0c9bb-e9d3-49ff-ff87-2bb8fff36a4d"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br5VbUFqYqaU"
      },
      "source": [
        "**check for nulls**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx1GpzNZYp01",
        "outputId": "463dc1d2-4287-474b-eced-f3379f02f416"
      },
      "source": [
        "train.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               False\n",
              "comment_text     False\n",
              "toxic            False\n",
              "severe_toxic     False\n",
              "obscene          False\n",
              "threat           False\n",
              "insult           False\n",
              "identity_hate    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cZzlsi1Y1wN",
        "outputId": "92eaec15-e12e-45a4-a0b5-47af14e08aa0"
      },
      "source": [
        "test.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id              False\n",
              "comment_text    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVwCHCsRY2aK"
      },
      "source": [
        "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "y = train[list_classes].values # y.shape (159571, 6)\n",
        "list_sentences_train = train[\"comment_text\"] # (159571,)\n",
        "list_sentences_test = test[\"comment_text\"] # (153164,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9A-6xdaMCU"
      },
      "source": [
        "# Tokenization \n",
        " sentence into unique words     \n",
        " ex) \"I love cats and love dogs\" -> [\"I\",\"love\",\"cats\",\"and\",\"dogs\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ7nCxq_aggD"
      },
      "source": [
        "# **Indexing**\n",
        "put the words in a dictionary-like structure and give them an index each     \n",
        "ex) {1:\"I\",2:\"love\",3:\"cats\",4:\"and\",5:\"dogs\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSjs54ypbMGM"
      },
      "source": [
        "# **Index Representation**\n",
        "represent the sequence of words in the comments in the form of index     \n",
        "ex) [\"I\",\"love\",\"cats\",\"and\",\"dogs\"] -> [1,2,3,4,5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zczDpgyfbey7"
      },
      "source": [
        "In Keras, all the above steps can be done in 4 lines of code     \n",
        "we have to *define the number of unique words* in our dictionary when tokenizing the sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT3x6dudaWGM"
      },
      "source": [
        "max_features = 20000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "# list_tokenized_train[:1] = [[688,75,1,126,130, ,,, ]]\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
        "# list_tokenized_test[:1] = [[2665,655,8849,656, ,,, ]]\n",
        "\n",
        "# tokenizer.word_counts = OrderedDict([('explanation', 1771),('why', 17818),('the', 496540),('edits', 9957), ,,, ])\n",
        "# tokenizer.word_index = {'the': 1,'to': 2,'of': 3,'and': 4, ,,, }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyJk-N4XBIbT",
        "outputId": "ac28d6bc-5e87-4d02-b5ee-933dd2fe2123"
      },
      "source": [
        "len(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVxvjHLOdU8b"
      },
      "source": [
        "**We may have a problem**     \n",
        "ex)        \n",
        "Comment #1: [8,9,3,7,3,6,3,6,3,6,2,3,4,9]      \n",
        "Comment #2: [1,2]      \n",
        "<br/>        \n",
        "\n",
        "we have to feed a stream of data that has a __consistent length(fixed number of features)__       \n",
        "<br/>\n",
        "<br/>\n",
        "     \n",
        "## We have to use \"padding\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB6RpbWldwL6"
      },
      "source": [
        "maxlen = 200\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen) # (159571, 200)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen) # (153164, 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubb6zyHMeIAF"
      },
      "source": [
        "Let the max length to be 200\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "__If we put it too short,__     \n",
        "we might lose some useful feature that could cost some accuracy points down \n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "__If we put it too long,__     \n",
        "LSTM cell will have to be larger to store the possible values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGqFiYuLemfr"
      },
      "source": [
        "One of the ways to go about it is \n",
        "<br/>\n",
        "to __see the distribution of the number of words in sentences__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "jdY2TB1UeW-B",
        "outputId": "4d2b10a0-fb15-414d-d5a0-a05ac78efed6"
      },
      "source": [
        "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]\n",
        "\n",
        "plt.hist(totalNumWords,bins = np.arange(0,410,10))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz_eJ9g-fLra"
      },
      "source": [
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLMmi8jGfOaq"
      },
      "source": [
        "# Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5Yqb9sDfkgS"
      },
      "source": [
        "# Sample structure\n",
        "![image](https://i.imgur.com/txJomEa.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVmOrwSMgGhK"
      },
      "source": [
        "# Input\n",
        "![image](https://i.imgur.com/uSjU4J7.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTv8DKCPgLWw"
      },
      "source": [
        "inp = Input(shape=(maxlen, )) #maxlen=200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqxZ0o8UgPDC"
      },
      "source": [
        "**Pass it to Embedding layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eWBe0iFgclY"
      },
      "source": [
        "embed_size = 128\n",
        "x = Embedding(max_features, embed_size)(inp) # max_features = 20000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j-6ArKKg2I6"
      },
      "source": [
        "**Output of Embedding layer is <br/> 3-D tensor of (None, 200, 128)**\n",
        "\n",
        "<br/>= array of sentence\n",
        "<br/>\n",
        "For each words(200), there is an array of 128 coordinates "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkLy6BmGhTwC"
      },
      "source": [
        "**Feed this Tensor into the LSTM layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AujnQb_jNu_4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_TB0k99h0Kh"
      },
      "source": [
        "# LSTM Layer     \n",
        "LSTM takes in a tensor of [Batch Size, Time Steps, Number of Inputs]     \n",
        "->     \n",
        "3-D tensor of (None, 200, 128) into the LSTM layer     \n",
        "->      \n",
        "Recursively run the LSTM model for 200 times      \n",
        "<br/>\n",
        "<br/>\n",
        "Want it to return the whole unrolled sequence of results      \n",
        "\n",
        "->     \n",
        "![image](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
        "The unrolled LSTM would give us a set of h0,h1,h2 until the last h"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8efMfEliF0S"
      },
      "source": [
        "x = LSTM(60, return_sequences=True,name='lstm_layer')(x)\n",
        "# Will receive a Tensor (None, 200, 60) , because we want the unrolled version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j05VDPwsje0S"
      },
      "source": [
        "# MaxPooling\n",
        "We need to reshape the 3D tensor into a 2D one     \n",
        "->     \n",
        "Use a __Global Max Pooling layer__      \n",
        "which is traditionally used in CNN problems to reduce the dimensionality of image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yryG7oKTi98i"
      },
      "source": [
        "x = GlobalMaxPool1D()(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7umNkMYOkCix"
      },
      "source": [
        "# Dropout Layer\n",
        "Pass it to a __Dropout layer__ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdBjob1rj0W4"
      },
      "source": [
        "x = Dropout(0.1)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx97aQpIkNVi"
      },
      "source": [
        "# Dense Layer\n",
        "Connect the output of drop out layer to a __densely connected layer__      \n",
        "and make them passes through a __RELU function__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc8Sln2lkKq_"
      },
      "source": [
        "x = Dense(50, activation=\"relu\")(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xieYE6XxkjwX"
      },
      "source": [
        "# Dropout Layer\n",
        "Feed the output into a Dropout layer again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF7n96UTkgVn"
      },
      "source": [
        "x = Dropout(0.1)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEZ-WzOwkwCI"
      },
      "source": [
        "# Dense Layer\n",
        "Finally, feed the output into a __Sigmoid layer__     \n",
        "Reason      \n",
        "we are trying to achieve a __binary classification__  for each of the 6 labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTHWSPo2ktWW"
      },
      "source": [
        "x = Dense(6, activation=\"sigmoid\")(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6QhkpgTlEsh"
      },
      "source": [
        "## Define the inputs, outputs and configure the learning process <br/><br/> Set Adam optimizer to optimize loss function <br/><br/> Set binary_crossentropy to be a loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23FuGxVflATX"
      },
      "source": [
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ONDDhLPl7yp"
      },
      "source": [
        "## A list of 32 padded, indexed sentence for each batch<br/><br/>Split 10% of the data as a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpBrSnbHl2YR",
        "outputId": "710adc3c-e2e6-4e71-99c1-03d2a0c28c49"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 2\n",
        "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 775s 172ms/step - loss: 0.1179 - accuracy: 0.8477 - val_loss: 0.0493 - val_accuracy: 0.9940\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 787s 175ms/step - loss: 0.0458 - accuracy: 0.9894 - val_loss: 0.0467 - val_accuracy: 0.9932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f40224fd0d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYcwcc04mO-X",
        "outputId": "7cf8de2c-8ecd-4df5-c734-9ef375dd2645"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 200, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "lstm_layer (LSTM)            (None, 200, 60)           45360     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                3050      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 2,608,716\n",
            "Trainable params: 2,608,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "591D-cyksfEv",
        "outputId": "2b68cce6-1908-420f-a7ae-ad297c150f79"
      },
      "source": [
        "model.predict(X_te[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9931177 , 0.5266132 , 0.939724  , 0.26442528, 0.8609197 ,\n",
              "        0.4475056 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9gMayrSog4C"
      },
      "source": [
        "# Tips\n",
        "Check if the outputs are performing as expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi1u-joNoglm",
        "outputId": "9a0b3206-d005-4cf7-c227-58132004acfa"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "# with a Sequential model\n",
        "get_3rd_layer_output = K.function([model.layers[0].input],\n",
        "                                  [model.layers[2].output])\n",
        "layer_output = get_3rd_layer_output([X_t[:1]])[0]\n",
        "layer_output.shape\n",
        "#print layer_output to see the actual data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 200, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VasMrnxo0Cw"
      },
      "source": [
        "# TODO\n",
        "\n",
        "\n",
        "*   Using Pre-trained models to boost accuracy and take advantage of existing efforts\n",
        "*   Hyper-parameter Tuning \n",
        "\n",
        "\n",
        "*   Early stopping during training\n",
        "*   Experiment with different architecture\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAr5UOIWpJ3x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}